{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zp5qGzyn_4V4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/psl_project3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkMqoyizAI7h",
        "outputId": "f8201f9f-519f-46b0-ca04-7bf010cb432f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "psl_project3_11_30_2am.ipynb  split_1  split_2\tsplit_3  split_4  split_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data for split 1\n",
        "Reviews from the train and test dataset along with their coresponding sentiment are combined into a data frame. This combined dataset is utilized for generating the vocabulary. By combining the reviews from the test and train it ensures the comprehensiveness of the vocabulary necessary for accurate predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AwBmgTaRAMwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/psl_project3/split_1/train.tsv\", sep='\\t', header=0, dtype=str)\n",
        "train['review'] = train['review'].str.replace('&lt;.*?&gt;', ' ', regex=True)\n",
        "\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/psl_project3/split_1/test.tsv\", sep='\\t', header=0, dtype=str)\n",
        "test['review'] = test['review'].str.replace('&lt;.*?&gt;', ' ', regex=True)\n",
        "\n",
        "test_y = pd.read_csv(\"/content/drive/MyDrive/psl_project3/split_1/test_y.tsv\", sep='\\t', header=0, dtype=str)"
      ],
      "metadata": {
        "id": "-U8b330IALsD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combine test & train reviews for split 1"
      ],
      "metadata": {
        "id": "gTY_tpW1AP3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine test reviews with its corresponding sentiment\n",
        "merged_df = pd.merge(test[['id', 'review']], test_y[['id', 'sentiment']], on='id', how='inner')\n",
        "new_test_df = merged_df[['review', 'sentiment']]\n",
        "\n",
        "#Combine test and train df\n",
        "combined_df = pd.concat([train, new_test_df], axis=0)\n",
        "\n",
        "#Remove the id column\n",
        "if 'id' in combined_df.columns:\n",
        "    combined_df.drop('id', axis=1, inplace=True)\n",
        "print(combined_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXSWokGGAUg5",
        "outputId": "1df5e911-85b6-4a5d-f6ac-669cefa02c70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      sentiment                                             review\n",
            "0             1  Naturally in a film who's main themes are of m...\n",
            "1             0  Afraid of the Dark left me with the impression...\n",
            "2             0  This has to be one of the biggest misfires eve...\n",
            "3             0  This is one of those movies I watched, and won...\n",
            "4             0  This movie was dreadful. Biblically very inacc...\n",
            "...         ...                                                ...\n",
            "24995         1  Where Da Vinci code introduced us to Dr. Rober...\n",
            "24996         0  I haven't seen Ishtar, but I did have the misf...\n",
            "24997         1  Peter Segal's 1995 commercial hit & now cult-c...\n",
            "24998         0  The reviewer in Variety said this was \\overwri...\n",
            "24999         0  I like bad films, but this thing is a steaming...\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Declare stopwords"
      ],
      "metadata": {
        "id": "NFPXx1SgAWnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\n",
        "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"you're\", \"you've\", \"you'll\",\n",
        "    \"you'd\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"she's\",\n",
        "    \"her\", \"hers\", \"herself\", \"it\", \"it's\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\n",
        "    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"that'll\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\n",
        "    \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
        "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\",\n",
        "    \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\",\n",
        "    \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\",\n",
        "    \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\",\n",
        "    \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\",\n",
        "    \"t\", \"can\", \"will\", \"just\", \"don\", \"don't\", \"should\", \"should've\", \"now\", \"d\", \"ll\", \"m\", \"o\", \"re\",\n",
        "    \"ve\", \"y\", \"ain\", \"aren\", \"aren't\", \"couldn\", \"couldn't\", \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"hadn\",\n",
        "    \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"isn\", \"isn't\", \"ma\", \"mightn\", \"mightn't\", \"mustn\",\n",
        "    \"mustn't\", \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \"shouldn't\", \"wasn\", \"wasn't\", \"weren\",\n",
        "    \"weren't\", \"won\", \"won't\", \"wouldn\", \"wouldn't\"\n",
        "]"
      ],
      "metadata": {
        "id": "n9Lm8lYFAa76"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create inital vocabulary"
      ],
      "metadata": {
        "id": "KdlE21EPAc9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=stop_words,          # Remove stop words\n",
        "    lowercase=True,                 # Convert to lowercase\n",
        "    ngram_range=(1, 4),             # Use 1- to 4-gram\n",
        "    min_df=0.001,                   # Minimum term frequency\n",
        "    max_df=0.5,                     # Maximum document frequency\n",
        "    token_pattern=r\"\\b[\\w+\\|']+\\b\"  # Use word tokenizer to treat words with apostrophes as a single token\n",
        ")\n",
        "dtm_train = vectorizer.fit_transform(combined_df['review'])"
      ],
      "metadata": {
        "id": "oPx9UnEdAgon"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trim vocabulary using LogisticRegression\n",
        "Then to reduce the vocabulary size to 1000 words , we employ Logistic Regression with an L1 penalty, a liblinear solver, and a C value of 0.548. The parameter C represents inverse of regularization strength, where smaller values specify stronger regularization. After trial and error, the parameter value of .548 of C resulted in exactly 1000 nonzero coefficients. These indices correspond to the features (words or phrases) that the model has identified as important for predicting sentiment.\n",
        "Therefore, the indices of 1000 nonzero coefficients are used to trim features from the vectorizer to obtain a final vocabulary of 1000 words."
      ],
      "metadata": {
        "id": "LmNzgxiUAjEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit LogisticRegression with l1 penalty on the transformed training data dtm_train\n",
        "logistic_reg_l1 = LogisticRegression(penalty='l1', solver='liblinear',max_iter=10000, C = .549)\n",
        "logistic_reg_l1.fit(dtm_train, combined_df['sentiment'])\n",
        "\n",
        "#Identify the indices where the coefficients obtained from the logistic regression model are non-zero\n",
        "nonzero_indices = np.where(logistic_reg_l1.coef_ != 0)[1]\n",
        "len(nonzero_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eiMoU9kAmBr",
        "outputId": "c47b88ee-009e-4191-fc94-488e90c03f55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1003"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain first 1000 non zero coefficients to trim vocabulary\n",
        "nonzero_indices = np.where(logistic_reg_l1.coef_ != 0)[1][:1000]\n",
        "len(nonzero_indices)\n",
        "\n",
        "#Generate the final vocabulary to length 1000\n",
        "final_vocab = np.array(vectorizer.get_feature_names_out())[nonzero_indices]\n",
        "len(final_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Ua8dCJA9tM",
        "outputId": "999a0ad3-d733-4163-d0b3-cc41bbb0b870"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save final vocabulary to myvocab.txt"
      ],
      "metadata": {
        "id": "UuvvGp6RBLeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/psl_project3/split_1/myvocab.txt'\n",
        "\n",
        "# Write the vocabulary to a text file\n",
        "with open(file_path, 'w') as file:\n",
        "    for word in final_vocab:\n",
        "        file.write(word + '\\n')"
      ],
      "metadata": {
        "id": "kz6V9KTfBQOX"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}